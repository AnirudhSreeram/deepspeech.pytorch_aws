[2021-11-11 00:09:24,177][torch.distributed.distributed_c10d][INFO] - Added key: store_based_barrier_key:1 to store for rank: 0
[2021-11-11 00:09:24,177][torch.distributed.distributed_c10d][INFO] - Rank 0: Completed store-based barrier for 1 nodes.
[2021-11-11 00:09:28,067][root][INFO] - Training is not really distributed, single rank. Deactivating buckets
[2021-11-11 00:09:28,067][root][INFO] - ShardedDDP bucket size: 0.00M parameters, model size 82.61M parameters
[2021-11-11 04:46:28,275][root][WARNING] - ShardedDDP detected that the trainable params changed, either because of eval/train mode or parameter freezing/unfreeze.
[2021-11-11 09:33:35,624][root][WARNING] - ShardedDDP detected that the trainable params changed, either because of eval/train mode or parameter freezing/unfreeze.
[2021-11-11 14:19:10,526][root][WARNING] - ShardedDDP detected that the trainable params changed, either because of eval/train mode or parameter freezing/unfreeze.
[2021-11-11 19:05:46,022][root][WARNING] - ShardedDDP detected that the trainable params changed, either because of eval/train mode or parameter freezing/unfreeze.
[2021-11-11 23:51:43,319][root][WARNING] - ShardedDDP detected that the trainable params changed, either because of eval/train mode or parameter freezing/unfreeze.
[2021-11-12 04:37:12,770][root][WARNING] - ShardedDDP detected that the trainable params changed, either because of eval/train mode or parameter freezing/unfreeze.
