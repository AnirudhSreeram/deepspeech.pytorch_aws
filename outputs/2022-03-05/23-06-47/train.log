[2022-03-05 23:06:49,557][torch.distributed.distributed_c10d][INFO] - Added key: store_based_barrier_key:1 to store for rank: 0
[2022-03-05 23:06:49,558][torch.distributed.distributed_c10d][INFO] - Rank 0: Completed store-based barrier for 1 nodes.
[2022-03-05 23:06:53,322][root][INFO] - Training is not really distributed, single rank. Deactivating buckets
[2022-03-05 23:06:53,322][root][INFO] - ShardedDDP bucket size: 0.00M parameters, model size 82.61M parameters
