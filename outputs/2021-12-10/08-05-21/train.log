[2021-12-10 08:05:23,607][torch.distributed.distributed_c10d][INFO] - Added key: store_based_barrier_key:1 to store for rank: 0
[2021-12-10 08:05:23,608][torch.distributed.distributed_c10d][INFO] - Rank 0: Completed store-based barrier for 1 nodes.
[2021-12-10 08:05:27,620][root][INFO] - Training is not really distributed, single rank. Deactivating buckets
[2021-12-10 08:05:27,620][root][INFO] - ShardedDDP bucket size: 0.00M parameters, model size 82.61M parameters
[2021-12-10 08:17:23,033][root][WARNING] - ShardedDDP detected that the trainable params changed, either because of eval/train mode or parameter freezing/unfreeze.
[2021-12-10 08:31:52,863][root][WARNING] - ShardedDDP detected that the trainable params changed, either because of eval/train mode or parameter freezing/unfreeze.
[2021-12-10 08:46:22,371][root][WARNING] - ShardedDDP detected that the trainable params changed, either because of eval/train mode or parameter freezing/unfreeze.
[2021-12-10 09:00:53,152][root][WARNING] - ShardedDDP detected that the trainable params changed, either because of eval/train mode or parameter freezing/unfreeze.
[2021-12-10 09:15:22,311][root][WARNING] - ShardedDDP detected that the trainable params changed, either because of eval/train mode or parameter freezing/unfreeze.
[2021-12-10 09:29:56,001][root][WARNING] - ShardedDDP detected that the trainable params changed, either because of eval/train mode or parameter freezing/unfreeze.
